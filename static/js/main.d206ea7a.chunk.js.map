{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["videoConstraints","height","width","maxWidth","facingMode","names","App","webcamRef","useRef","useState","setModel","videoWidth","videoHeight","loadModel","a","tf","loadedModel","console","log","onCapture","model","current","video","readyState","cnvs","document","getElementById","ctx","getContext","clearRect","rawImgTensor","fromPixels","inputs","shape","slice","inputTensorWidth","inputTensorHeight","inputTensor","resizeBilinear","div","expandDims","performance","now","executeAsync","then","res","font","textBaseline","i","boxes","scores","classes","valid_detections","boxes_data","dataSync","scores_data","classes_data","valid_detections_data","x1","y1","x2","y2","klass","score","toFixed","strokeStyle","lineWidth","strokeRect","fillStyle","textWidth","measureText","textHeight","parseInt","fillRect","fillText","len","length","finally","useEffect","_","setInterval","className","style","position","top","zIndex","id","backgroundColor","audio","ref","screenshotQuality","screenshotFormat","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"+bAKMA,EAAmB,CACrBC,OAAQ,KACRC,MAAO,KACPC,SAAU,QACVC,WAAY,eAIVC,EAAQ,CAAC,SAAU,UAAW,MAAO,aAAc,WAAY,MAAO,QAAS,QAAS,OAAQ,gBAAiB,eAAgB,YAAa,gBAAiB,QAAS,OAAQ,MAAO,MAAO,QAAS,QAAS,MAAO,WAAY,OAAQ,QAAS,UAAW,WAAY,WAAY,UAAW,MAAO,WAAY,UAAW,OAAQ,YAAa,cAAe,OAAQ,eAAgB,iBAAkB,aAAc,YAAa,gBAAiB,SAAU,aAAc,MAAO,OAAQ,QAAS,QAAS,OAAQ,SAAU,QAAS,WAAY,SAAU,WAAY,SAAU,UAAW,QAAS,QAAS,OAAQ,QAAS,QAAS,eAAgB,MAAO,eAAgB,SAAU,KAAM,SAAU,QAAS,SAAU,WAAY,aAAc,YAAa,OAAQ,UAAW,OAAQ,eAAgB,OAAQ,QAAS,OAAQ,WAAY,aAAc,aAAc,cAiK/0BC,MA/Jf,WACI,IAAMC,EAAYC,iBAAO,MACzB,EAA0BC,mBAAS,MAAnC,mBAAcC,GAAd,WACA,EAAoCD,mBAAS,KAA7C,mBAAOE,EAAP,KACA,GADA,KACsCF,mBAAS,MAA/C,mBAAOG,EAAP,KAEMC,GAFN,KAEe,uCAAG,4BAAAC,EAAA,sEAEYC,IAXR,sBASJ,cAERC,EAFQ,OAGdN,EAASM,GACTC,QAAQC,IAAI,iBAJE,kBAKPF,GALO,2CAAH,sDAQTG,EAAS,uCAAG,WAAOC,GAAP,mCAAAN,EAAA,sDAGmB,qBAAtBP,EAAUc,SAAiD,OAAtBd,EAAUc,SAA2D,IAAvCd,EAAUc,QAAQC,MAAMC,YAA8B,OAAVH,IAGhHE,EAAQf,EAAUc,QAAQC,MAC1BX,EAAaW,EAAMX,WACnBC,EAAcU,EAAMV,YAG1BL,EAAUc,QAAQC,MAAMpB,MAAQS,EAChCJ,EAAUc,QAAQC,MAAMrB,OAASW,GAE3BY,EAAOC,SAASC,eAAe,aAChCxB,MAAQS,EACba,EAAKvB,OAASW,GAGRe,EAAMH,EAAKI,WAAW,OACxBC,UAAU,EAAG,EAAGtB,EAAUc,QAAQC,MAAMX,WAAYJ,EAAUc,QAAQC,MAAMV,aAG1EkB,EAAef,IAAWgB,WAAWT,GApB2F,EAwBxFF,EAAMY,OAAO,GAAGC,MAAMC,MAAM,EAAG,GAxByD,mBAwB/HC,EAxB+H,KAwB7GC,EAxB6G,KAyBhIC,EAActB,KAAQ,WACxB,OAAOA,IAASuB,eAAeR,EAAc,CAACK,EAAkBC,IAAoBG,IAAI,KAAOC,WAAW,MAG9FC,YAAYC,MAC5BtB,EACKuB,aAAaN,GACbO,MAAK,SAACC,GAEH,IAAMC,EAAO,kBACbnB,EAAImB,KAAOA,EACXnB,EAAIoB,aAAe,MAEnB,IAMIC,EANJ,cAAmDH,EAAnD,GAAOI,EAAP,KAAcC,EAAd,KAAsBC,EAAtB,KAA+BC,EAA/B,KACMC,EAAaJ,EAAMK,WACnBC,EAAcL,EAAOI,WACrBE,EAAeL,EAAQG,WACvBG,EAAwBL,EAAiBE,WAAW,GAG1D,IAAKN,EAAI,EAAGA,EAAIS,IAAyBT,EAAG,CACxC,MAAuBK,EAAWnB,MAAU,EAAJc,EAAiB,GAATA,EAAI,IAApD,mBAAKU,EAAL,KAASC,EAAT,KAAaC,EAAb,KAAiBC,EAAjB,KAKM3D,GAHN0D,GAAMjD,IADN+C,GAAM/C,GAKAV,GAFN4D,GAAMjD,IADN+C,GAAM/C,GAIAkD,EAAQzD,EAAMmD,EAAaR,IAC3Be,EAAQR,EAAYP,GAAGgB,QAAQ,GAGrCrC,EAAIsC,YAAc,UAClBtC,EAAIuC,UAAY,EAChBvC,EAAIwC,WAAWT,EAAIC,EAAIzD,EAAOD,GAG9B0B,EAAIyC,UAAY,UAChB,IAAMC,EAAY1C,EAAI2C,YAAYR,EAAQ,IAAMC,GAAO7D,MACjDqE,EAAaC,SAAS1B,EAAM,IAClCnB,EAAI8C,SAASf,EAAIC,EAAIU,EAAY,EAAGE,EAAa,GAErD,IAAKvB,EAAI,EAAGA,EAAIS,IAAyBT,EAAG,CACxC,MAAkBK,EAAWnB,MAAU,EAAJc,EAAiB,GAATA,EAAI,IAA/C,mBAAKU,EAAL,KAASC,EAAT,KACAD,GAAM/C,EACNgD,GAAM/C,EACN,IAAMkD,EAAQzD,EAAMmD,EAAaR,IAC3Be,EAAQR,EAAYP,GAAGgB,QAAQ,GAGrCrC,EAAIyC,UAAY,UAChBzC,EAAI+C,SAASZ,EAAQ,IAAMC,EAAOL,EAAIC,GAG5BlB,YAAYC,MAE1B,OAAOG,KAEVD,MAAK,SAACC,GAGH,IAFA,IAAIG,EAAI,EACF2B,EAAM9B,EAAI+B,OACT5B,EAAI2B,GACP5D,IAAW8B,EAAIG,IACfA,OAGP6B,SAAQ,WACL9D,IAAWe,GACXf,IAAWsB,OAhGT,2CAAH,sDA6Hf,OApBAyC,qBAAU,WAMN/D,MACK6B,MAAK,SAACmC,GACHhE,MACAE,QAAQC,IAAI,oBAEf0B,KAAK/B,GACL+B,MAAK,SAAC5B,GACHC,QAAQC,IAAI,wBACZ8D,YAAY7D,EAAW,IAAKH,QAErC,IAKC,sBAAKiE,UAAU,MAAf,UACI,qBAAKC,MAAO,CAAEC,SAAU,WAAYC,IAAK,MAAOC,OAAQ,QAAxD,SACI,wBAAQC,GAAG,WAAWpF,MAAOS,EAAYV,OAAQW,EAAasE,MAAO,CAAEK,gBAAiB,mBAE5F,qBAAKL,MAAO,CAAEC,SAAU,WAAYC,IAAK,OAAzC,SACI,cAAC,IAAD,CACII,OAAO,EACPF,GAAG,MACHG,IAAKlF,EAELmF,kBAAmB,EACnBC,iBAAiB,aACjB3F,iBAAkBA,UC3JvB4F,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBlD,MAAK,YAAkD,IAA/CmD,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEF7E,SAASC,eAAe,SAM1BkE,M","file":"static/js/main.d206ea7a.chunk.js","sourcesContent":["import \"./App.css\";\nimport React, { useEffect, useState, useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport Webcam from \"react-webcam\";\n\nconst videoConstraints = {\n    height: 1080,\n    width: 1920,\n    maxWidth: \"100vw\",\n    facingMode: \"environment\",\n};\nconst yolov5s_model_url = \"yolov5s/model.json\";\nconst yolov5n_model_url = \"yolov5n/model.json\";\nconst names = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"];\n\nfunction App() {\n    const webcamRef = useRef(null);\n    const [model, setModel] = useState(null);\n    const [videoWidth, setVideoWidth] = useState(960);\n    const [videoHeight, setVideoHeight] = useState(640);\n\n    const loadModel = async () => {\n        /** @type {tf.GraphModel} */\n        const loadedModel = await tf.loadGraphModel(yolov5n_model_url);\n        setModel(loadedModel);\n        console.log(\"Model loaded.\");\n        return loadedModel;\n    };\n\n    const onCapture = async (model) => {\n        // console.log(\"Capturing\");\n        // Check data is available\n        if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4 && model !== null) {\n            // Get Video Properties\n            /** @type {HTMLVideoElement} */\n            const video = webcamRef.current.video;\n            const videoWidth = video.videoWidth;\n            const videoHeight = video.videoHeight;\n\n            // Set video width\n            webcamRef.current.video.width = videoWidth;\n            webcamRef.current.video.height = videoHeight;\n\n            const cnvs = document.getElementById(\"myCanvas\");\n            cnvs.width = videoWidth;\n            cnvs.height = videoHeight;\n            // cnvs.style.position = \"absolute\";\n\n            const ctx = cnvs.getContext(\"2d\");\n            ctx.clearRect(0, 0, webcamRef.current.video.videoWidth, webcamRef.current.video.videoHeight);\n\n            /** @type {tf.Tensor3D} */\n            const rawImgTensor = tf.browser.fromPixels(video);\n            // console.log(`rawImgTensor shape: ${rawImgTensor.shape}`);\n\n            /** @type {tf.GraphModel} */\n            const [inputTensorWidth, inputTensorHeight] = model.inputs[0].shape.slice(1, 3); // [640, 640]\n            const inputTensor = tf.tidy(() => {\n                return tf.image.resizeBilinear(rawImgTensor, [inputTensorWidth, inputTensorHeight]).div(255.0).expandDims(0);\n            });\n            // console.log(`inputTensor shape: ${inputTensor.shape}`);\n            let startTime = performance.now();\n            model\n                .executeAsync(inputTensor)\n                .then((res) => {\n                    // Font options.\n                    const font = \"16px sans-serif\";\n                    ctx.font = font;\n                    ctx.textBaseline = \"top\";\n\n                    const [boxes, scores, classes, valid_detections] = res;\n                    const boxes_data = boxes.dataSync();\n                    const scores_data = scores.dataSync();\n                    const classes_data = classes.dataSync();\n                    const valid_detections_data = valid_detections.dataSync()[0];\n\n                    let i;\n                    for (i = 0; i < valid_detections_data; ++i) {\n                        let [x1, y1, x2, y2] = boxes_data.slice(i * 4, (i + 1) * 4);\n                        x1 *= videoWidth;\n                        x2 *= videoWidth;\n                        y1 *= videoHeight;\n                        y2 *= videoHeight;\n                        const width = x2 - x1;\n                        const height = y2 - y1;\n                        const klass = names[classes_data[i]];\n                        const score = scores_data[i].toFixed(2);\n\n                        // Draw the bounding box.\n                        ctx.strokeStyle = \"#00FFFF\";\n                        ctx.lineWidth = 4;\n                        ctx.strokeRect(x1, y1, width, height);\n\n                        // Draw the label background.\n                        ctx.fillStyle = \"#00FFFF\";\n                        const textWidth = ctx.measureText(klass + \":\" + score).width;\n                        const textHeight = parseInt(font, 10); // base 10\n                        ctx.fillRect(x1, y1, textWidth + 4, textHeight + 4);\n                    }\n                    for (i = 0; i < valid_detections_data; ++i) {\n                        let [x1, y1, ,] = boxes_data.slice(i * 4, (i + 1) * 4);\n                        x1 *= videoWidth;\n                        y1 *= videoHeight;\n                        const klass = names[classes_data[i]];\n                        const score = scores_data[i].toFixed(2);\n\n                        // Draw the text last to ensure it's on top.\n                        ctx.fillStyle = \"#000000\";\n                        ctx.fillText(klass + \":\" + score, x1, y1);\n                    }\n\n                    let endTime = performance.now();\n                    // console.log(`Took ${endTime - startTime} milliseconds`);\n                    return res;\n                })\n                .then((res) => {\n                    let i = 0;\n                    const len = res.length;\n                    while (i < len) {\n                        tf.dispose(res[i]);\n                        i++;\n                    }\n                })\n                .finally(() => {\n                    tf.dispose(rawImgTensor);\n                    tf.dispose(inputTensor);\n                });\n            // console.dir(`numTensors: ${tf.memory().numTensors}`);\n        }\n    };\n\n    /* \n    Run only once\n     */\n    useEffect(() => {\n        // console.log(tfgl.version_webgl);\n        // console.log(tf.getBackend());\n        // tfgl.webgl.forceHalfFloat();\n        // var maxSize = tfgl.webgl_util.getWebGLMaxTextureSize(tfgl.version_webgl);\n        // console.log(maxSize);\n        tf.ready()\n            .then((_) => {\n                tf.enableProdMode();\n                console.log(\"tfjs is ready\");\n            })\n            .then(loadModel)\n            .then((loadedModel) => {\n                console.log(\"Test model is loaded\");\n                setInterval(onCapture, 333, loadedModel);\n            });\n    }, []);\n\n    // let supportedConstraints = navigator.mediaDevices.getSupportedConstraints();\n    // console.log(supportedConstraints);\n    return (\n        <div className=\"App\">\n            <div style={{ position: \"absolute\", top: \"0px\", zIndex: \"9999\" }}>\n                <canvas id=\"myCanvas\" width={videoWidth} height={videoHeight} style={{ backgroundColor: \"transparent\" }} />\n            </div>\n            <div style={{ position: \"absolute\", top: \"0px\" }}>\n                <Webcam\n                    audio={false}\n                    id=\"img\"\n                    ref={webcamRef}\n                    // width={640}\n                    screenshotQuality={1}\n                    screenshotFormat=\"image/jpeg\"\n                    videoConstraints={videoConstraints}\n                />\n            </div>\n        </div>\n    );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}